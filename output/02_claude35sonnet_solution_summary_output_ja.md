# LLMプロンプト復元コンペティションにおけるトップ5ソリューションの要約

## 概要

このドキュメントは、LLMプロンプト復元コンペティションにおけるトップ5参加者のソリューションを要約したものです。このコンペティションは、テキスト変換に使用されたプロンプトを復元することが課題で、ソリューションは敵対的攻撃から洗練されたモデルアンサンブルまで多岐にわたりました。

## 共通のテーマ

トップソリューションにはいくつかの共通テーマが見られました：

1. "lucrarea"トークンの使用：多くのソリューションが、評価に使用されたsentence-t5モデルで特別な性質を持つように見える"lucrarea"トークンを活用しました。
2. 平均プロンプト：ほとんどのソリューションが、何らかの形で最適化された平均プロンプトを組み込んでいました。
3. ファインチューニングされた言語モデル：特にMistral 7Bなど、様々なファインチューニングされたモデルがプロンプトの生成や改善に使用されました。
4. アンサンブルアプローチ：複数の技術を組み合わせることで、多くの場合最良の結果が得られました。
5. データ生成：トレーニングのための多様で高品質なデータセットの作成が重要でした。

## 1位のソリューション：敵対的攻撃

### 主要コンポーネント

1. 予測に追加される敵対的文字列
2. Mistral 7BとGemma-7B-1.1-itモデルの混合
3. 多様な予測動詞のセット

### 技術詳細

- 追加された文字列: " 'it 's ' something Think A Human Plucrarealucrarealucrarealucrarealucrarealucrarealucrarealucrarea"
- この文字列はsentence-t5モデルにおける</s>トークンの挙動を利用しています
- "lucrarea"はモデルのTensorFlowバージョンで</s>の代替として機能します
- 異なる開始動詞を持つ複数のモデルにより、予測の多様性を確保しています

## 2位のソリューション：Team Danube

### 主要コンポーネント

1. 最適化された平均プロンプト
2. 埋め込み予測モデル
3. LLM予測
4. ブルートフォース最適化

### 技術詳細

- ブルートフォーストークン組み合わせによって最適化された平均プロンプト
- H2O LLM Studioを使用してトレーニングされた埋め込み予測モデル
- 最適化の初期化に使用されるLLM予測
- 最終予測は、few-shot予測、LLM予測、平均プロンプト、最適化された埋め込み文字列を組み合わせています

### データとクロスバリデーション

- 主にGemmaを含む様々なモデルを使用してデータを生成
- 約350サンプルの検証セットを作成
- CVとLBスコア間に良好な相関

## 3位のソリューション

### 主要コンポーネント

1. 平均プロンプトテンプレート
2. 完全なプロンプト予測のためにファインチューニングされたMistralForCausalLM
3. フィルター/ゲートとしてのMistralForSequenceClassification
4. タグ予測のためのMistralForCausalLM
5. プロンプトテンプレート選択のためのクラスタリングモデル

### 技術詳細

- 平均プロンプト + タグ + 完全プロンプト（ゲートを通過した場合）
- LLMとプロンプトバリエーションを含むデータ生成プロセス
- 不正確なプロンプト予測をフィルタリングするゲートモデル
- 書き換えプロンプトの側面を予測するタグモデル
- 異なるサンプルグループに対して最適な平均プロンプトを見つけるクラスタリングアプローチ

## 4位のソリューション：ST5トークナイザー攻撃

### 主要コンポーネント

1. 最適化された平均プロンプト
2. 追加のプロンプト生成のためのMistral 7B
3. "lucrarea"トークンの活用

### 技術詳細

- 0.69のスコアを出すように最適化された平均プロンプト
- "Modify this text by"という単純な応答プレフィックスを使用したMistral 7B
- PyTorch版とTensorFlow版におけるST5トークナイザーの挙動の詳細な分析

## 5位のソリューション

### 主要コンポーネント

1. 広範なデータ生成
2. Robertaモデルを使用した埋め込み予測
3. プロンプト生成のためのLLM（Mistral 7B）
4. プロンプトの再ランク付けと連結
5. "lucrarea"トークンの活用

### 技術詳細

- 様々なLLMと公開データセットからデータを生成
- T5埋め込みを予測するようにトレーニングされたRobertaモデル
- プロンプト検索にコサイン類似度を使用
- スコア改善のためのプロンプト連結と再ランク付け
- 類似性を高めるために</s>の代替として"lucrarea"トークンを使用

## 結論

このコンペティションのトップソリューションは、基礎となるsentence-t5モデルへの深い理解と、特定の評価指標を最適化するための創造的なアプローチを示しました。敵対的技術の使用、洗練されたモデルアンサンブル、慎重なデータ準備が高スコアを達成する上で重要な要因となりました。