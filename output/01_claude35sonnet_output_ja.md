# LLMプロンプト復元コンペティション

## アジェンダ

- コンペティション概要
- 評価指標
- 我々のアプローチ
  - データ作成
  - 平均プロンプト検索
  - プロンプト修正
  - トピックワード予測
- 結論

## コンペティション概要

- 目標：与えられたテキストを変換するために使用されたLLMプロンプトを復元する
- データセット：Gemmaによって書き換えられた1300以上の原文ペア
- 期間：2024年2月28日 - 2024年4月17日
- 焦点：効果的なLLMプロンプト技術の理解

## 評価指標

- sentence-t5-baseを使用して埋め込みベクトルを計算
- シャープ化コサイン類似度（SCS）を指数3で使用
- SCSは不正解に対する寛大なスコアを減衰
- 高スコアには正確な単語マッチングが重要
- nullの回答はエラーとなる

## 我々のアプローチ：データ作成

- LBと高い相関を持つ検証データを作成
- ソース：
  - 公開データセット
  - Gemma、Gemini、GPT4を使用した自己生成データセット
- 40-90の平均プロンプトを使用して相関データを抽出
- 高スコアの平均プロンプトを効率的に作成するのに役立つ

## 我々のアプローチ：平均プロンプト検索

- "Rewrite"から始め、nltk/wordnetの語彙を検索
- 人間が理解可能な文章に焦点を当てる
- 最終的な平均プロンプト（パブリック/プライベートLBで0.66スコア）： 
**'Revise or Revamp this text and phrase to convey the task yet incorporating a plenteous subject, its initial purport while retaining atmosphere yet preserving any intended heartfelt tone, while keeping writing style, making only key improvements to an succinct, dispassionate, and elegant coherence.'**

## 我々のアプローチ：プロンプト修正（1/4）

1. 原文の「テキストの種類」を抽出（Mistral 7B）
   - テキストの種類を予測（例：メール、エッセイ、手紙）
   - 「text and phrase」を予測された種類に置き換え
   - パブリックLBスコアを+0.003〜0.005向上
   - テキストの種類がある版とない版の2バージョンを作成

## 我々のアプローチ：プロンプト修正（2/4）

2. 「トーン」の差異を抽出（Mistral 7B）
   - 原文と書き換えられたテキスト間のトーンの差異を予測
   - 文の中央にトーンを挿入
   - 予測されたトーンの前に「more」を追加
   - パブリックLBスコアを+0.015向上

## 我々のアプローチ：プロンプト修正（3/4）

3. 「トピック」を抽出（DeBERTa-v3-large and DeBERTa-v3-base）
   - 原文と書き換えられたテキスト間の単語の差異を抽出
   - rewrite_promptに出現する単語を分類するモデルを訓練
   - 抽出された単語を平均プロンプトに挿入
   - パブリックLBスコアを+0.01〜0.02向上

## 我々のアプローチ：プロンプト修正（4/4）

4. ロジックベースの後処理
   - 書き換えられたテキストから太字の単語を抽出（データセットの7-9%）
   - 書き換えられたテキストに「Verse」がある場合「song」を追加（データセットの7-9%）
   - パブリックLBスコアを+0.005向上

## 我々のアプローチ：トピックワード予測（1/2）

- 書き換えられたテキストとrewrite_promptの両方に存在する単語を予測
- トークン化の問題に対処するための2つの方法：
  1. 複数トークンの単語の最初のトークンのみラベル付け
  2. 対象単語のすべてのトークンをラベル付け

## 我々のアプローチ：トピックワード予測（2/2）

- トレーニングの詳細：
  - パブリックデータセットからノイズのないデータセットを使用
  - モデル：deberta-v3-large and deberta-v3-base
  - 重複と原文の単語を削除する後処理
  - 最適な閾値と挿入位置を探索
  - 予測を組み合わせてCVスコアを0.6530から0.6902に改善

| モデル | 方法 | CVスコア |
|-------|------|---------|
| 平均プロンプト | - | 0.6530 |
| deberta-v3-large + deberta-v3-base | 方法1+方法2+探索 | 0.6902 |

## 結論

- 我々のアプローチはLLM、ML、ロジックベースの技術を組み合わせた
- 主要コンポーネント：
  - 高品質な検証データ
  - 最適化された平均プロンプト
  - 多面的なプロンプト修正
  - 高度なトピックワード予測
- 評価指標で大幅な改善を達成
- 精密なプロンプトエンジニアリングの重要性を実証