# LLMプロンプト復元コンペティション

## アジェンダ

- コンペティション概要
- 評価指標
- 我々のアプローチ
  - データ作成
  - 平均プロンプト検索
  - プロンプト修正
  - トピックワード予測
- トップ5ソリューション概要
- 結論

## コンペティション概要

- 目標：与えられたテキストを変換するために使用されたLLMプロンプトを復元する
- データセット：1300以上のオリジナルテキストとGemmaによる書き換え版のペア
- 期間：2024年2月28日 - 2024年4月17日
- 焦点：効果的なLLMプロンプト技術の理解

## 評価指標

- sentence-t5-baseを使用して埋め込みベクトルを計算
- 指数3のシャープ化コサイン類似度（SCS）を使用
- SCSは不正解に対する寛大なスコアを抑制
- 高スコアには正確な単語マッチングが重要
- ヌル回答はエラーとなる

## 我々のアプローチ：データ作成

- LBと高い相関を持つ検証データを作成
- ソース：
  - 公開データセット
  - Gemma、Gemini、GPT4を使用した自己生成データセット
- 40-90の平均プロンプトを使用して相関データを抽出
- 高スコアの平均プロンプトを効率的に作成するのに役立った

## 我々のアプローチ：平均プロンプト検索

- "Rewrite"から始め、nltk/wordnetの語彙を検索
- 人間が理解しやすい文章に焦点を当てた
- 最終的な平均プロンプト（公開/非公開LBで0.66のスコア）：
**'Revise or Revamp this text and phrase to convey the task yet incorporating a plenteous subject, its initial purport while retaining atmosphere yet preserving any intended heartfelt tone, while keeping writing style, making only key improvements to an succinct, dispassionate, and elegant coherence.'**

## 我々のアプローチ：プロンプト修正（1/4）

1. オリジナルテキストの「テキストの種類」を抽出（Mistral 7B）
   - テキストの種類を予測（例：メール、エッセイ、手紙）
   - "text and phrase"を予測された種類に置き換え
   - 公開LBスコアを+0.003〜0.005向上
   - テキストの種類ありとなしの2バージョンを作成

## 我々のアプローチ：プロンプト修正（2/4）

2. 「トーン」の差異を抽出（Mistral 7B）
   - オリジナルと書き換えテキスト間のトーンの差異を予測
   - 文の中央にトーンを挿入
   - 予測されたトーンの前に "more" を追加
   - 公開LBスコアを+0.015向上

## 我々のアプローチ：プロンプト修正（3/4）

3. 「トピック」を抽出（DeBERTa-v3-largeとDeBERTa-v3-base）
   - オリジナルと書き換えテキスト間の単語の差異を抽出
   - rewrite_promptに現れる単語を分類するモデルを訓練
   - 抽出された単語を平均プロンプトに挿入
   - 公開LBスコアを+0.01〜0.02向上

## 我々のアプローチ：プロンプト修正（4/4）

4. ロジックベースの後処理
   - 書き換えテキストから太字の単語を抽出（データセットの7-9%）
   - 書き換えテキストに "Verse" がある場合 "song" を追加（データセットの7-9%）
   - 公開LBスコアを+0.005向上

## 我々のアプローチ：トピックワード予測（1/2）

- 書き換えテキストとrewriteプロンプトの両方に存在する単語を予測
- トークン化の問題に対処する2つの方法：
  1. 複数トークンの単語の最初のトークンのみにラベル付け
  2. 対象単語のすべてのトークンにラベル付け

## 我々のアプローチ：トピックワード予測（2/2）

- トレーニングの詳細：
  - 公開データセットからノイズのないデータセットを使用
  - モデル：deberta-v3-largeとdeberta-v3-base
  - 重複とオリジナルテキストからの単語を削除する後処理
  - 最適なしきい値と挿入位置を探索
  - 組み合わせた予測によりCVスコアを0.6530から0.6902に改善

| モデル | 方法 | CVスコア |
|-------|------|---------|
| 平均プロンプト | - | 0.6530 |
| deberta-v3-large + deberta-v3-base | 方法1+方法2+探索 | 0.6902 |

## トップ5ソリューション概要

### 共通のテーマ

1. "lucrarea"トークンの使用
2. 平均プロンプト
3. ファインチューニングされた言語モデル
4. アンサンブルアプローチ
5. データ生成

## 1-2位
### 1位：敵対的攻撃

- 予測に敵対的な文字列を追加
- Mistral 7BとGemma-7B-1.1-itモデルの組み合わせ
- 多様な予測動詞セット

### 2位：チームダニューブ

- 最適化された平均プロンプト
- 埋め込み予測モデル
- LLM予測
- ブルートフォース最適化

## 3-4位
### 3位

- 平均プロンプトテンプレート
- 完全プロンプト予測のためのファインチューニングされたMistralForCausalLM
- フィルター/ゲートとしてのMistralForSequenceClassification
- タグ予測のためのMistralForCausalLM
- プロンプトテンプレート選択のためのクラスタリングモデル

### 4位：ST5トークナイザー攻撃

- 最適化された平均プロンプト
- 追加のプロンプト生成のためのMistral 7B
- "lucrarea"トークンの活用

## 5位
### 5位

- 広範なデータ生成
- Robertaモデルを使用した埋め込み予測
- プロンプト生成のためのLLM（Mistral 7B）
- プロンプトの再ランク付けと連結
- "lucrarea"トークンの活用

## 結論

- 我々のアプローチはLLM、ML、ロジックベースの技術を組み合わせた
- 主要コンポーネント：
  - 高品質な検証データ
  - 最適化された平均プロンプト
  - 多面的なプロンプト修正
  - 高度なトピックワード予測
- 評価指標で大幅な改善を達成
- 精密なプロンプトエンジニアリングの重要性を実証

このコンペティションのトップソリューションは以下を示した：
- 基礎となるsentence-t5モデルの深い理解
- 特定の評価指標に対する創造的な最適化アプローチ
- 敵対的技術の使用
- 洗練されたモデルアンサンブル
- 慎重なデータ準備

これらの要因は高スコアを達成し、LLMプロンプト復元の分野を進展させる上で重要であった。